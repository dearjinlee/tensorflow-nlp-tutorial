# Jiphyeonjeon Season 2 - Beginners' Group
* 수정 및 업데이트 요청 : [고현웅](https://github.com/hyunwoongko)(gusdnd852@naver.com), [박은빈](https://github.com/42cosmos)(cosmos.42@icloud.com), [양수영](https://github.com/aiaaua)(yse00800@gmail.com)
* 초급반 스케쥴: [구글 시트](https://docs.google.com/spreadsheets/d/1pwkvIwf3T1bo2y7aXmSYPN6otlPKJl9kCJHaze0H3KY/edit#gid=0)
<br><br>

## Table of Contents
- [Textbook](#Textbook)
- [Presentations](#Presentations)
<br><br>

## Textbook
[딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)
<br><br>

## Presentations
- 01: 텍스트 전처리 전반부 1 ~ 5 챕터
  >- [Video](https://youtu.be/2bbIxIscfCA), [Presentation](./presentations/season2-1조-텍스트전처리_전반부.pdf)
  >- Keywords: Tokenization, Cleaning, Normalization, Stemming, Lemmatization, Stopword, Regular Expression
  >- Team: 김경환, 박은빈, 신승배

- 02: 텍스트 전처리 후반부 6 ~ 10 챕터
  >- [Video](https://youtu.be/1c8MP9hPt5c), [Presentation](./presentations/season2-2조_텍스트전처리_후반부.pdf)
  >- Keywords: Integer Encoding, Padding, One-Hot Encoding, Splitting Data, Text Preprocessing Tools for Korean Text
  >- Team: 이창훈, 이문형, 유예림 

- 03: 언어 모델

  >- [Video](https://youtu.be/my__g5LeEOU), [Presentation](./presentations/season2-3조_언어모델.pdf)
  >- Keywords: Languagel Model, Statistical Languagel Model, SLM, n-gram
  >- Team: 최수진, 허영운, 조정원

- 04: 카운트 기반의 단어 표현
  >- [Video](https://youtu.be/zMgn0-tO0Nc), [Presentation](./presentations/season2-4조_카운트기반단어표현.pdf)
  >- Keywords: Bag of Words, Document-Term Matrix, Term Frequency-Inverse Document Frequency  
  >- Team: 기대현, 조다희, 홍다솔
  
- 05: 벡터 유사도

  >- [Video](https://youtu.be/aVjcZ7BnTxA), [Presentation](./presentations/season2-5조_벡터유사도.pdf)
  >- Keywords: Vector Similarity, Cosine Similarity, Euclidean distance
  >- Team: 조성철, 지현구, 박서영

- 06: 토픽 모델링

  >- [Video](https://youtu.be/PyuCL7AyuBg), [Presentation](./presentations/season2-6조-토픽모델링.pdf)
  >- Keywords: Latent Semantic Analysis, Singular Value Decomposition, Latent Dirichlet Allocation
  >- Team: 김준태, 박준현(발표자), 전인성

- 07: 머신러닝 개요

  >- [Video](https://youtu.be/Ke1PBYhxgC8), [Presentation](./presentations/season2_7조_머신러닝개요.pdf)
  >- Keywords: Machine Learning, Confusion Matrix, Linear Regression, Auto Diff, Auto Gradient
  >- Team: 최희욱(발표자), 김유진, 장호섭


- 08: 머신 러닝 개요 후반부 5 ~ 9 챕터

  >- [Video](https://www.youtube.com/watch?v=uuJAO5hXvmA), [Presentation](./presentations/season2-8조-머신러닝_후반부.pdf)
  >- Keywords: Logistic Regression, Vector, Matrix, Softmax Regression
  >- Team: 주혜신(발표자), 장영찬(발표자), 차경묵

- 09: 딥러닝 개요 전반부 1 ~ 5 챕터

  >- [Video](https://youtu.be/6GERl_6DYl8), [Presentation](./presentations/season2-9조-딥러닝개요_전반부.pdf) 
  >- Keywords: Perceptron, Activation function, Loss function, Optimizer, BackPropagation, Overfitting, Gradient Vanishing & Exploding
  >- Team: 금예은(발표자)

- 10: 딥러닝 개요 후반부 6 ~ 10 챕터  

  >- [Video](https://youtu.be/ceNum507t-c), [Presentation](./presentations/season2-10조-딥러닝개요-후반부.pdf) 
  >- Keywords: Keras, Sequential API, Functional API, Subclassing API, MLP, n-gram, Language Model, NNLM
  >- Team: 차민기(발표자), 성민석(발표자), 김민정(발표자)
  
- 11: 순환 신경망 (Recurrent neural Network) ; 01) ~ 07) 

  >- [Video](https://youtu.be/5ZXjAGx7iQw), [Presentation](./presentations/season2-11조-순환신경망(RNN).pdf) 
  >- Keywords: Keras, RNN, LSTM, GRU, RNNLM, CHAR-RNNLM
  >- Team: 김기동(발표자), 이주형(발표자), 최선웅(발표자)

- 13: 워드 임베딩 (Word Embedding) 6 ~ 12 챕터 

  >- [Video](https://youtu.be/H-f0oHh5fPs), [Presentation](./presentations/season2-13조-워드_임베딩_후반부.pdf) 
  >- Keywords: Word Embedding, FastText, Keras Embedding, ELMo, Embedding Visualization, Recommendation System using Document Embedding, Average Word Embedding
  >- Team: 배수현(발표자), 변재경(발표자)
  
- 16: 태깅 작업 (Tagging Task) 1 ~ 7 챕터

  >- [Video](https://www.youtube.com/watch?v=In-Y2jHjgnc), [Presentation](./presentations/season2-16조-테깅작업.pdf) 
  >- Keywords: Tagging Task, Bidirectional RNN, Keras, Sequence Labeling, LSTM, CRF, Named Entity Recognition, BiLSTM-CRF
  >- Team: 손한기(발표자), 김경리(발표자), 이동민(발표자)
  
  - 20: 트랜스포머 (Transformer)

  >- [Video](https://youtu.be/7xlusHKocqo), [Presentation](./presentations/season2_20조_트랜스포머_pdf) 
  >- Keywords: Transformer, attention is all you need, self-attention, masked multi-head attention, positional encoding, seq2seq, encoder, decoder, Feed Forward Network, residual connection, layer normalization
  >- Team: 박상효(발표자), 은승현(발표자), 한다솜(발표자)

- 19: 어텐션 메커니즘 (Attention Mechanism)

  >- [Video](https://youtu.be/772LlwrXEok), [Presentation](./presentations/season2-19조-어텐션메커니즘.pdf) 
  >- Keywords: Attention Mechanism, Attention score Function, Dot-Product Attention, Bahdanau Attention, Keras, BiLSTM, IMDB
  >- Team: 김두진(발표자), 박경민(발표자), 유병관(발표자)

- 22: 텍스트 요약 (Text Summarization)

  >- [Video](https://www.youtube.com/watch?v=XG-weJ06bOQ), [Presentation](./presentations/season2-22조-Summarization.pdf) 
  >- Keywords: Text Rank, Text summarization, T5
  >- Team: 도정민(발표자), 조희준(발표자), 김산

- 23: 질의응답 (Question & Answering, QA)

  >- [Video](https://youtu.be/aH5-gbBRUX0), [Presentation](./presentations/season2-23조_질의응답(QA).pdf) 
  >- Keywords: RNN, Question&Answering model, Memory network, End-to-End Memory network, 
  >- Team: 박동호(발표자), 윤재두(발표자), 서혜영(발표자)
